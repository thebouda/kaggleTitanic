{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as ttt\n",
    "\n",
    "# first we get the data\n",
    "testPath = \"Data/test.csv\"\n",
    "trainPath = \"Data/train.csv\"\n",
    "genderSubmissionPath = \"Data/gender_submission.csv\"\n",
    "\n",
    "testPDRaw = pd.read_csv(testPath)\n",
    "trainPDRaw = pd.read_csv(trainPath)\n",
    "genderSubPDRaw = pd.read_csv(genderSubmissionPath)\n",
    "\n",
    "# merge the test data too\n",
    "testDataMerge= pd.merge(genderSubPDRaw,testPDRaw,on = 'PassengerId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge test and train data in order to do the same changes\n",
    "combine = [trainPDRaw,testPDRaw]\n",
    "# unuseful data might be the passanger ticket\n",
    "# remove passanger ticket\n",
    "for dataset in combine:\n",
    "    dataset.drop( columns= ['Ticket'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>55</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>436</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived    0    1\n",
       "Title             \n",
       "Capt        1    0\n",
       "Col         1    1\n",
       "Countess    0    1\n",
       "Don         1    0\n",
       "Dr          4    3\n",
       "Jonkheer    1    0\n",
       "Lady        0    1\n",
       "Major       1    1\n",
       "Master     17   23\n",
       "Miss       55  127\n",
       "Mlle        0    2\n",
       "Mme         0    1\n",
       "Mr        436   81\n",
       "Mrs        26   99\n",
       "Ms          0    1\n",
       "Rev         6    0\n",
       "Sir         0    1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# considering the names we could reduce it Mr, Mrs, Miss, Col, Master to make it easier\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(trainPDRaw.Title,trainPDRaw.Survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex    female  male\n",
       "Title              \n",
       "0         186     0\n",
       "1           0   517\n",
       "2         125     0\n",
       "3           0    40\n",
       "4           1    15\n",
       "5           2     5"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.crosstab(trainPDRaw.Title,trainPDRaw.Survived)\n",
    "# we replace: mlle and Ms by miss, \n",
    "for dataset in combine:\n",
    "    dataset.Title.replace(['Ms', 'Mlle','Mme'], 'Miss', inplace = True)\n",
    "    # we considered these individuals to be in a lower social ranking so that's why the difference between the 'rare' class\n",
    "    dataset.Title.replace(['Capt','Col','Rev', 'Dr'],'Other', inplace = True) \n",
    "    dataset.Title.replace(['Countess','Don','Dona','Jonkheer','Major','Lady','Sir'], 'Rare', inplace = True)\n",
    "\n",
    "\n",
    "    dataset.Title.replace( 'Miss','0', inplace = True)\n",
    "    dataset.Title.replace( 'Mr','1', inplace = True)\n",
    "    dataset.Title.replace( 'Mrs','2', inplace = True)\n",
    "    dataset.Title.replace( 'Master','3', inplace = True)\n",
    "    dataset.Title.replace( 'Other','4', inplace = True)\n",
    "    dataset.Title.replace( 'Rare','5', inplace = True)\n",
    "\n",
    "    dataset.Title= dataset.Title.astype(int)\n",
    "\n",
    "    dataset.Embarked.replace( 'S','0', inplace = True)\n",
    "    dataset.Embarked.replace( 'Q','1', inplace = True)\n",
    "    dataset.Embarked.replace( 'C','2', inplace = True)\n",
    "    \n",
    "\n",
    "pd.crosstab(trainPDRaw.Title, trainPDRaw.Sex)\n",
    "# print(testPDRaw.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see where are we at\n",
    "# now that we have modified the name into title we drop the name column\n",
    "\n",
    "for data in combine:\n",
    "    data.drop(columns= ['Name'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we replace male and female by 1 and 0\n",
    "for data in combine:\n",
    "    data.Sex.replace('female', '1',inplace=True)\n",
    "    data.Sex.replace('male','0', inplace =True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we raw the histogram for the fares\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(combine[0].Fare)\n",
    "# combine[0].Fare.describe()\n",
    "# we round the columns of fare to see better\n",
    "for data in combine:\n",
    "    data.Fare = data.Fare.round(decimals = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of      PassengerId  Survived  Pclass Sex   Age  SibSp  Parch  Fare Cabin  \\\n",
      "0              1         0       3   0  22.0      1      0   1.0   NaN   \n",
      "1              2         1       1   1  38.0      1      0   4.0   C85   \n",
      "2              3         1       3   1  26.0      0      0   1.0   NaN   \n",
      "3              4         1       1   1  35.0      1      0   4.0  C123   \n",
      "4              5         0       3   0  35.0      0      0   1.0   NaN   \n",
      "..           ...       ...     ...  ..   ...    ...    ...   ...   ...   \n",
      "886          887         0       2   0  27.0      0      0   3.0   NaN   \n",
      "887          888         1       1   1  19.0      0      0   4.0   B42   \n",
      "888          889         0       3   1   NaN      1      2   3.0   NaN   \n",
      "889          890         1       1   0  26.0      0      0   4.0  C148   \n",
      "890          891         0       3   0  32.0      0      0   1.0   NaN   \n",
      "\n",
      "    Embarked  Title  \n",
      "0          0      1  \n",
      "1          2      2  \n",
      "2          0      0  \n",
      "3          0      2  \n",
      "4          0      1  \n",
      "..       ...    ...  \n",
      "886        0      4  \n",
      "887        0      0  \n",
      "888        0      0  \n",
      "889        2      1  \n",
      "890        1      1  \n",
      "\n",
      "[891 rows x 11 columns]>\n"
     ]
    }
   ],
   "source": [
    "# does it make sense to take into account the ticket even though the class is already detailed?\n",
    "# we createa fare ranges\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Fare'] <= 3, 'Fare' ] = 0\n",
    "    dataset.loc[(dataset['Fare'] <=8) & (dataset['Fare'] >3), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] <=12) & (dataset['Fare'] >8), 'Fare'] = 2\n",
    "    dataset.loc[(dataset['Fare'] <30) & (dataset['Fare'] >12), 'Fare'] = 3\n",
    "    dataset.loc[dataset['Fare'] >=30,  'Fare'] = 4\n",
    "\n",
    "print(combine[0].head)\n",
    "\n",
    "# farePclass=pd.crosstab(combine[0].Fare,combine[0].Pclass)\n",
    "# fareSurv = pd.crosstab(combine[0].Fare,combine[0].Survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop the cabin and the embarked port\n",
    "for data in combine:\n",
    "    data.drop( columns=['Cabin'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(combine[1].Embarked.value_counts())\n",
    "# print(combine[1].isna().sum())\n",
    "\n",
    "# we have to deal with the fact that there's a number for age that we should fill, probably with class and fare \n",
    "# get the age mean of the different classes and variance \n",
    "# do the same with the fare\n",
    "# for that we use group by, use it on the train sample\n",
    "ageClasses = combine[0].groupby('Pclass').mean()\n",
    "ageClassesVar = combine[0].groupby('Pclass').std()\n",
    "ageFare = combine[0].groupby('Fare').mean()\n",
    "ageFareVar = combine[0].groupby('Fare').std()\n",
    "# we get the correlation matrix: the passenger class has a higher correlation with the age, hence it would make sense to model it accordingly\n",
    "\n",
    "corrMat = combine[0].corr('pearson')\n",
    "\n",
    "# print(ageClassesVar)\n",
    "# print(ageClasses)\n",
    "# print(ageFareVar)\n",
    "# print(ageFare)\n",
    "# print(corrMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the variance and mean of pclass\n",
    "# meanPclassDF = ageClasses.Age\n",
    "# varPclassDF = ageClassesVar.Age\n",
    "\n",
    "# for data in combine:\n",
    "#     condC1 = (data.Pclass == 1 )& (data.Age.isnull())\n",
    "#     condC2 = (data.Pclass == 2 )& (data.Age.isnull())\n",
    "#     condC3 = (data.Pclass == 3 )& (data.Age.isnull())\n",
    "\n",
    "#     data.Age.replace(condC1, )\n",
    "# # now we replace nan for the mean and standard deviation\n",
    "\n",
    "# print(combine[0].loc[(combine[0].Pclass == 1 ) \n",
    "# & (combine[0].Age.isnull()) \n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare Embarked  Title\n",
      "0            1         0       3    0   22      1      0   1.0        0      1\n",
      "1            2         1       1    1   38      1      0   4.0        2      2\n",
      "2            3         1       3    1   26      0      0   1.0        0      0\n",
      "3            4         1       1    1   35      1      0   4.0        0      2\n",
      "4            5         0       3    0   35      0      0   1.0        0      1\n",
      "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare Embarked  Title\n",
      "0            1         0       3    0   22      1      0   1.0        0      1\n",
      "1            2         1       1    1   38      1      0   4.0        2      2\n",
      "2            3         1       3    1   26      0      0   1.0        0      0\n",
      "3            4         1       1    1   35      1      0   4.0        0      2\n",
      "4            5         0       3    0   35      0      0   1.0        0      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baldo\\Documents\\Progra\\kaggleTitanic\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "c:\\Users\\baldo\\Documents\\Progra\\kaggleTitanic\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# by doing a combination of pclass and sex we get the age\n",
    "import numpy\n",
    "age_guess = numpy.zeros((2,3))\n",
    "age_guessMed = numpy.zeros((2,3))\n",
    "for dataset in combine:\n",
    "    dataset.Pclass = dataset.Pclass.astype(int)\n",
    "    dataset.Sex = dataset.Sex.astype(int)\n",
    "    # dataset.Age = dataset.Age.astype(int)\n",
    "\n",
    "    dataset.Pclass.astype(int,copy = False)\n",
    "    for i in range(0,2): # sex\n",
    "        for j in range(1,4): # pclass\n",
    "            ageGuess = dataset.loc[(dataset['Sex'] == i) & (dataset['Pclass'] == j)]['Age'].dropna()\n",
    "            \n",
    "            # print(dataset.Sex.dtype)\n",
    "            # print(dataset.loc[dataset['Fare'] <= 3, 'Fare' ])\n",
    "            age_guessMean =ageGuess.mean()\n",
    "            ageMed = ageGuess.median()\n",
    "            age_guess[i,j-1] = int(age_guessMean)\n",
    "            age_guessMed[i,j-1]= int(ageMed)\n",
    "    \n",
    "    for i in range(0,2): # sex\n",
    "        for j in range(0,3): # pclass     \n",
    "            dataset.Age.loc[(dataset.Age.isnull()) & ( dataset.Sex == i) & (dataset.Pclass == j+1)] = age_guess[i,j]   \n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "            # print( dataset.loc[dataset['Age'].isnull()])\n",
    "\n",
    "    print(trainPDRaw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create age band\n",
    "# 13- 19 teenager\n",
    "# baby 0-4\n",
    "# child 5-12\n",
    "# young adult 20-30\n",
    "# adult until 50\n",
    "# older than 50\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.Age= dataset.Age.astype(int)\n",
    "    dataset.loc[dataset['Age'] <= 3, 'Age' ] = 0 #'baby'\n",
    "    dataset.loc[(dataset['Age'] <= 12) & (dataset.Age >3), 'Age' ] = 1 # child\n",
    "    dataset.loc[(dataset['Age'] <= 19) & (dataset.Age >12), 'Age' ] = 2  #'teenager'\n",
    "    dataset.loc[(dataset['Age'] <= 30) & (dataset.Age >19), 'Age' ] = 3#'young'\n",
    "    dataset.loc[(dataset['Age'] <= 50) & (dataset.Age >30), 'Age' ] =4 #'adult'\n",
    "    dataset.loc[dataset['Age'] > 50, 'Age' ] = 5#'senior'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       2\n",
      "Title          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(trainPDRaw.isnull().sum())\n",
    "# in the train theres two rows that does not have a embarked\n",
    "# in the test there's one row that does not have the fare\n",
    "# so we remove both\n",
    "trainPDRaw.dropna(subset =['Embarked'], inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we got some values that are nan so we remove them\n",
    "\n",
    "# trainPDRaw.dropna(subset = ['Embarked'], inplace= True)\n",
    "# print(trainPDRaw.isnull().sum())\n",
    "# 3 we must do the join between the test set and the survived, with the id of the passenger\n",
    "testDataMergeFinal= pd.merge(genderSubPDRaw,testPDRaw,on = 'PassengerId')\n",
    "testDataMergeFinal.dropna(subset= ['Fare'], inplace = True)\n",
    "# print(testDataMergeFinal.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# prepare the data\n",
    "from sklearn.model_selection import train_test_split as ttt\n",
    "\n",
    "yTest = testDataMergeFinal.Survived\n",
    "xTest = testDataMergeFinal.drop(['Survived','PassengerId'], axis = 1)\n",
    "\n",
    "xTrain =trainPDRaw.drop(['Survived','PassengerId'],axis = 1 )\n",
    "yTrain = trainPDRaw.Survived\n",
    "\n",
    "# split train data\n",
    "xSplit_Train,xSplit_Test,ySplit_Train,ySplit_Test = ttt(xTrain,yTrain,test_size=0.3,random_state= 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.90262172284645\n",
      "96.40287769784173\n"
     ]
    }
   ],
   "source": [
    "# try some models\n",
    "\n",
    "# lda\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "clfLDA = LDA()\n",
    "\n",
    "clfLDA.fit(xSplit_Train,numpy.array(ySplit_Train).reshape(numpy.array(ySplit_Train).size))\n",
    "ySplit_pred = clfLDA.predict(xSplit_Test)\n",
    "# why functions accuracy does not work\n",
    "\n",
    "# accuracy = functions.getAccuracy(ySplit_pred,ySplit_Test)\n",
    "expected_Reshaped = numpy.array(ySplit_Test).reshape(ySplit_Test.size)\n",
    "test = numpy.array(expected_Reshaped == numpy.array(ySplit_pred)).sum()\n",
    "accuracy  = test /expected_Reshaped.size *100\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "# definitive test\n",
    "yDef_pred = clfLDA.predict(xTest)\n",
    "expected_Reshaped = numpy.array(yTest).reshape(yTest.size)\n",
    "test = numpy.array(expected_Reshaped == numpy.array(yDef_pred)).sum()\n",
    "accuracy  = test /expected_Reshaped.size *100\n",
    "print(accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15abced4188db35c83b661c0f4def9b023fcfdcf8f2071ac5896473ee4691a96"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
